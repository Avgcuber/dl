{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYG4mgcm9rma",
        "outputId": "8485f046-372f-43a0-b2e2-d1e07e8f1156"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2917 - accuracy: 0.9164\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 13s 7ms/step - loss: 0.1435 - accuracy: 0.9577\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.1072 - accuracy: 0.9676\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0908 - accuracy: 0.9716\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0747 - accuracy: 0.9757\n",
            "313/313 - 1s - loss: 0.0767 - accuracy: 0.9766 - 612ms/epoch - 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5, 10), dtype=float32, numpy=\n",
              "array([[3.13297505e-06, 6.94928076e-07, 7.52242486e-05, 6.21002109e-04,\n",
              "        3.72370107e-10, 5.17045692e-07, 4.47503606e-13, 9.99086022e-01,\n",
              "        3.79684434e-06, 2.09633901e-04],\n",
              "       [1.13100860e-07, 4.10859539e-05, 9.99873877e-01, 6.46879780e-05,\n",
              "        2.27157908e-17, 2.27999772e-06, 2.13529134e-07, 1.14437851e-13,\n",
              "        1.76185331e-05, 2.47857962e-12],\n",
              "       [6.59772681e-08, 9.98375297e-01, 2.67218536e-04, 3.91403228e-05,\n",
              "        8.97681603e-05, 4.60145566e-06, 2.19962640e-05, 3.30293900e-04,\n",
              "        8.45469709e-04, 2.60801135e-05],\n",
              "       [9.99956131e-01, 1.05610035e-10, 1.65812598e-05, 1.24879449e-07,\n",
              "        1.32023636e-08, 8.81152482e-06, 2.21302844e-06, 5.73146690e-06,\n",
              "        2.77604766e-08, 1.03799784e-05],\n",
              "       [1.11115901e-06, 3.65586716e-09, 1.42627482e-06, 6.69176501e-08,\n",
              "        9.82445061e-01, 2.34889353e-06, 2.82243946e-07, 5.10192476e-05,\n",
              "        1.40024565e-06, 1.74972899e-02]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "#importing TensorFlow Library\n",
        "import tensorflow as tf\n",
        "\n",
        "#Loading Dataset\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "#Spliting Dataset into Training and Testing Set\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "#Normailizing The Data\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "#creating Sequential Model\n",
        "model = tf.keras.models.Sequential([\n",
        " tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        " tf.keras.layers.Dense(128, activation='relu'),\n",
        " tf.keras.layers.Dropout(0.2),\n",
        " tf.keras.layers.Dense(10)\n",
        "])\n",
        "\n",
        "# prediction on First Training Sample\n",
        "predictions = model(x_train[:1]).numpy()\n",
        "\n",
        "\n",
        "# converting Raw Output values into probabilities using Softmax\n",
        "tf.nn.softmax(predictions).numpy()\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "# Calculating Loss For First Training Sample\n",
        "loss_fn(y_train[:1], predictions).numpy()\n",
        "\n",
        "# Compiling Model\n",
        "model.compile(optimizer='adam',\n",
        " loss=loss_fn,\n",
        " metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, epochs=5)\n",
        "model.evaluate(x_test, y_test, verbose=2)\n",
        "\n",
        "# Creating Probablity Model\n",
        "probability_model = tf.keras.Sequential([\n",
        " model,\n",
        " tf.keras.layers.Softmax()\n",
        "])\n",
        "probability_model(x_test[:5])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def unit_step(v):\n",
        " return 1 if v >= 0 else 0\n",
        "\n",
        "def perceptron_model(x, w, b):\n",
        " v = np.dot(w, x) + b\n",
        " y = unit_step(v)\n",
        " return y\n",
        "\n",
        "def NOT_logic_function(x):\n",
        " w_NOT = -1\n",
        " b_NOT = 0.5\n",
        " return perceptron_model(x, w_NOT, b_NOT)\n",
        "\n",
        "def AND_logic_function(x):\n",
        " w_AND = np.array([1, 1])\n",
        " b_AND = -1.5\n",
        " return perceptron_model(x, w_AND, b_AND)\n",
        "\n",
        "def OR_logic_function(x):\n",
        " w_OR = np.array([1, 1])\n",
        " b_OR = -0.5\n",
        " return perceptron_model(x, w_OR, b_OR)\n",
        "\n",
        "def XOR_logic_function(x):\n",
        " y1 = AND_logic_function(x)\n",
        " y2 = OR_logic_function(x)\n",
        " y3 = NOT_logic_function(y1)\n",
        " final_x = np.array([y2, y3])\n",
        " return AND_logic_function(final_x)\n",
        "\n",
        "test_cases = [\n",
        " (0, 0),\n",
        " (0, 1),\n",
        " (1, 0),\n",
        " (1, 1),\n",
        "]\n",
        "\n",
        "print(\"\\n\\n Results:\")\n",
        "\n",
        "for test in test_cases:\n",
        " x1, x2 = test\n",
        " output = XOR_logic_function(np.array([x1, x2]))\n",
        " print(f\"\\tXOR({x1}, {x2}) = {output}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P15tMeEDBjkD",
        "outputId": "e18a1c04-bd44-4633-de47-79e9b2452b19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            " Results:\n",
            "\tXOR(0, 0) = 0\n",
            "\tXOR(0, 1) = 1\n",
            "\tXOR(1, 0) = 1\n",
            "\tXOR(1, 1) = 0\n"
          ]
        }
      ]
    }
  ]
}